{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of HbA1c Measurement on Hospital Readmission Rates: Analysis of 70,000 Clinical Database Patient Records\n",
    "\n",
    "#### Created by: \n",
    "Paz Bunis (pazbunis@gmail.com)\n",
    "#### based on:\n",
    "Beata Strack, Jonathan P. DeShazo, Chris Gennings, et al., “Impact of HbA1c\n",
    "Measurement on Hospital Readmission Rates: Analysis of 70,000 Clinical Database\n",
    "Patient Records,” BioMed Research International, vol. 2014, 11 pages, 2014."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import style as style\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "style.use('ggplot')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from kmodes import kmodes\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "encounters = pd.read_csv('dataset/diabetic_data.csv')\n",
    "msk = np.random.rand(len(encounters)) < 0.9\n",
    "encounters_train = encounters[msk]\n",
    "encounters_test = encounters[~msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Descriptive Statistics\n",
    "### 1.1. Gender vs. other attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1. Gender vs. Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "females_age_grouping = encounters_train[encounters_train.gender == 'Female'].groupby('age').size()\n",
    "males_age_grouping = encounters_train[encounters_train.gender == 'Male'].groupby('age').size()\n",
    "fig, axs = plt.subplots(1,2, figsize=(9,3))\n",
    "axs[0].set_ylabel(\"encounters\")\n",
    "axs[1].set_ylabel(\"encounters\")\n",
    "fig.tight_layout(pad=4)\n",
    "females_age_grouping.plot.bar(ax = axs[0], title = 'Females')\n",
    "males_age_grouping.plot.bar(ax = axs[1], title = 'Males', color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2. Gender vs. Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "females_race_grouping = encounters_train[encounters_train.gender == 'Female'].groupby('race').size()\n",
    "males_race_grouping = encounters_train[encounters_train.gender == 'Male'].groupby('race').size()\n",
    "fig, axs = plt.subplots(1,2, figsize=(9,3))\n",
    "axs[0].set_ylabel(\"encounters\")\n",
    "axs[1].set_ylabel(\"encounters\")\n",
    "fig.tight_layout(pad=4)\n",
    "females_race_grouping.plot.bar(ax = axs[0], title = 'Females')\n",
    "males_race_grouping.plot.bar(ax = axs[1], title = 'Males', color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3. Gender vs. Readmission Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "females_readmission_grouping = encounters_train[encounters_train.gender == 'Female'].groupby('readmitted').size()\n",
    "males_readmission_grouping = encounters_train[encounters_train.gender == 'Male'].groupby('readmitted').size()\n",
    "fig, axs = plt.subplots(1,2, figsize=(9,3))\n",
    "axs[0].set_ylabel(\"encounters\")\n",
    "axs[1].set_ylabel(\"encounters\")\n",
    "fig.tight_layout(pad=4)\n",
    "females_readmission_grouping.plot.bar(ax = axs[0], title = 'Females')\n",
    "males_readmission_grouping.plot.bar(ax = axs[1], title = 'Males', color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4. Gender vs. Most Frequently Used ICD-9 Codes\n",
    "(All three diagnosis types are combined to one column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fem_diags_projection = encounters_train[encounters_train.gender == 'Female'][['diag_1', 'diag_2', 'diag_3']]\n",
    "fem_diags_arr = [fem_diags_projection[['diag_1']],fem_diags_projection[['diag_2']],fem_diags_projection[['diag_3']]]\n",
    "fem_comb_diags = pd.concat(fem_diags_arr, axis=1).stack().reset_index(drop=True)\n",
    "\n",
    "male_diags_projection = encounters_train[encounters_train.gender == 'Male'][['diag_1', 'diag_2', 'diag_3']]\n",
    "male_diags_arr = [male_diags_projection[['diag_1']],male_diags_projection[['diag_2']],male_diags_projection[['diag_3']]]\n",
    "male_comb_diags = pd.concat(male_diags_arr, axis=1).stack().reset_index(drop=True)\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(9,4))\n",
    "axs[0].set_ylabel(\"encounters\")\n",
    "axs[0].set_xlabel(\"ICD-9 Code\")\n",
    "axs[1].set_ylabel(\"encounters\")\n",
    "axs[1].set_xlabel(\"ICD-9 Code\")\n",
    "fig.tight_layout(pad=4)\n",
    "fem_comb_diags.value_counts().head().plot.bar(ax = axs[0], title = 'Females')\n",
    "male_comb_diags.value_counts().head().plot.bar(ax = axs[1], title = 'Males', color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Days in Hospital and A1c Test Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1. Days in Hospital vs. Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "females_hospital_time_grouping = encounters_train[encounters_train.gender == 'Female'].groupby('time_in_hospital').size()\n",
    "males_hospital_time_grouping = encounters_train[encounters_train.gender == 'Male'].groupby('time_in_hospital').size()\n",
    "fig, axs = plt.subplots(1,2, figsize=(9,3))\n",
    "axs[0].set_ylabel(\"encounters\")\n",
    "axs[0].set_xlabel(\"days\")\n",
    "axs[1].set_ylabel(\"encounters\")\n",
    "axs[1].set_xlabel(\"days\")\n",
    "\n",
    "fig.tight_layout(pad=4)\n",
    "females_hospital_time_grouping.plot.bar(ax = axs[0], title = 'Females')\n",
    "males_hospital_time_grouping.plot.bar(ax = axs[1], title = 'Males', color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2. Days in Hospital vs. Age Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_group1= encounters_train[encounters_train.age.isin(['[0-10)','[10-20)', '[20-30)', '[30-40)'])]\n",
    "age_group2= encounters_train[encounters_train.age.isin(['[40-50)', '[50-60)', '[60-70)'])]\n",
    "age_group3= encounters_train[encounters_train.age.isin(['[70-80)', '[80-90), [90-100)'])]\n",
    "group1_hospital_time = age_group1.groupby('time_in_hospital').size()\n",
    "group2_hospital_time = age_group2.groupby('time_in_hospital').size()\n",
    "group3_hospital_time = age_group3.groupby('time_in_hospital').size()\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(9,3))\n",
    "# axs[0].set_ylabel(\"encounters\")\n",
    "# axs[0].set_xlabel(\"days\")\n",
    "# axs[1].set_ylabel(\"encounters\")\n",
    "# axs[1].set_xlabel(\"days\")\n",
    "\n",
    "fig.tight_layout(pad=4)\n",
    "group1_hospital_time.plot.bar(ax = axs[0], title = '[0-40)')\n",
    "group2_hospital_time.plot.bar(ax = axs[1], title = '[40-70)')\n",
    "group3_hospital_time.plot.bar(ax = axs[2], title = '[70-100)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3. A1c test results vs. Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "females_A1C_grouping = encounters_train[encounters_train.gender == 'Female'].groupby('A1Cresult').size()\n",
    "males_A1C_grouping = encounters_train[encounters_train.gender == 'Male'].groupby('A1Cresult').size()\n",
    "fig, axs = plt.subplots(1,2, figsize=(9,3))\n",
    "axs[0].set_ylabel(\"encounters\")\n",
    "axs[0].set_xlabel(\"days\")\n",
    "axs[1].set_ylabel(\"encounters\")\n",
    "axs[1].set_xlabel(\"days\")\n",
    "\n",
    "fig.tight_layout(pad=4)\n",
    "females_A1C_grouping.plot.bar(ax = axs[0], title = 'Females')\n",
    "males_A1C_grouping.plot.bar(ax = axs[1], title = 'Males', color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4. A1c test results vs. Age Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_group1= encounters_train[encounters_train.age.isin(['[0-10)','[10-20)', '[20-30)', '[30-40)'])]\n",
    "age_group2= encounters_train[encounters_train.age.isin(['[40-50)', '[50-60)', '[60-70)'])]\n",
    "age_group3= encounters_train[encounters_train.age.isin(['[70-80)', '[80-90), [90-100)'])]\n",
    "group1_hospital_time = age_group1.groupby('A1Cresult').size()\n",
    "group2_hospital_time = age_group2.groupby('A1Cresult').size()\n",
    "group3_hospital_time = age_group3.groupby('A1Cresult').size()\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(9,3))\n",
    "# axs[0].set_ylabel(\"encounters\")\n",
    "# axs[0].set_xlabel(\"days\")\n",
    "# axs[1].set_ylabel(\"encounters\")\n",
    "# axs[1].set_xlabel(\"days\")\n",
    "\n",
    "fig.tight_layout(pad=4)\n",
    "group1_hospital_time.plot.bar(ax = axs[0], title = '[0-40)')\n",
    "group2_hospital_time.plot.bar(ax = axs[1], title = '[40-70)')\n",
    "group3_hospital_time.plot.bar(ax = axs[2], title = '[70-100)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Other Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: add more Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Is Testing HbA1c  Associated With a Reduced Rate of Readmission?\n",
    "Our null hypothesis $H_0$ is that there is no correlation between the HbA1c test and the rate of readmission.\n",
    "In order to test this, we will use the Fisher exact test and the Chi-square test (which is supposed to be better for larger numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proj = encounters_train[['A1Cresult', 'readmitted']]\n",
    "ct = pd.crosstab(proj.A1Cresult, proj.readmitted, margins=True)\n",
    "ct['readmitted'] = ct['<30'] \n",
    "ct['not_readmitted'] = ct['>30'] + ct['NO']\n",
    "ct = ct[['readmitted', 'not_readmitted', 'All']]\n",
    "N_readmitted_tested = ct.readmitted.All - ct.readmitted['None']\n",
    "N_readmitted_not_tested = ct.readmitted['None']\n",
    "N_not_readmitted_tested = ct.not_readmitted.All - ct.not_readmitted['None']\n",
    "N_not_readmitted_not_tested = ct.not_readmitted['None']\n",
    "\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Fisher Exact Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "contingency_table = [[N_readmitted_tested, N_readmitted_not_tested],[N_not_readmitted_tested, N_not_readmitted_not_tested]]\n",
    "odds_ratio, p_val = scipy.stats.fisher_exact(contingency_table)\n",
    "print('Odds ratio: ' + str(odds_ratio))\n",
    "print('P-value: ' + str(p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see here, we get $p < 0.001$ and an odds-ratio which is significantly lower than 1, so we should reject the null hypothesis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Chi-Square Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statistic, p_val, _, _ =scipy.stats.chi2_contingency(contingency_table, correction=True)\n",
    "print('Statistic value: ' + str(statistic))\n",
    "print('P-value: ' + str(p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got a high $\\chi^2$ value and $p < 0.001$, so we again conclude that we should reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Is Drug Prescription or Dosage Change Associated With a Reduced Rate of Readmission? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our null hypothesis  $H_0$  is that there is no correlation between drug prescription or dosage change and the rate of readmission. \n",
    "As before, we use the Fisher exact test and the Chi-square test for added robustness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drug_change_columns = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', \n",
    "                       'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose', \n",
    "                       'miglitol', 'troglitazone', 'tolazamide', 'examide', 'citoglipton', 'insulin', \n",
    "                       'glyburide-metformin', 'glipizide-metformin', 'glimepiride-pioglitazone', \n",
    "                       'metformin-rosiglitazone', 'metformin-pioglitazone', 'diabetesMed']\n",
    "drug_df = encounters_train[drug_change_columns]\n",
    "indicators = drug_df.apply(lambda x: (\"Up\" in x) or (x.diabetesMed == \"Yes\"), axis=1) \n",
    "df = pd.DataFrame(data = {'prescribed_or_upped': indicators, 'readmitted': encounters_train['readmitted']})\n",
    "ct = pd.crosstab(df.prescribed_or_upped, df.readmitted, margins=True)\n",
    "ct['readmitted'] = ct['<30'] \n",
    "ct['not_readmitted'] = ct['>30'] + ct['NO']\n",
    "ct = ct[['readmitted', 'not_readmitted', 'All']]\n",
    "print(ct)\n",
    "N_readmitted_prescribed_or_upped = ct.readmitted[True]\n",
    "N_readmitted_not_prescribed_or_upped = ct.readmitted[False]\n",
    "N_not_readmitted_prescribed_or_upped = ct.not_readmitted[True]\n",
    "N_not_readmitted_not_prescribed_or_upped = ct.not_readmitted[False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Fisher Exact Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contingency_table = [[N_readmitted_prescribed_or_upped, N_readmitted_not_prescribed_or_upped],\n",
    "                     [N_not_readmitted_prescribed_or_upped, N_not_readmitted_not_prescribed_or_upped]]\n",
    "odds_ratio, p_val = stats.fisher_exact(contingency_table)\n",
    "print('Odds ratio: ' + str(odds_ratio))\n",
    "print('P-value: ' + str(p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see here, we get $p < 0.001$ and an odds-ratio which is significantly higher than 1, so we should reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Chi-Square Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statistic, p_val, _, _ = stats.chi2_contingency(contingency_table, correction=True)\n",
    "print('Statistic value: ' + str(statistic))\n",
    "print('P-value: ' + str(p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got a high $\\chi^2$ value and $p < 0.001$, so we again conclude that we should reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Clustering and Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Defining a Metric "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are clustreting categorical data, one logical option is using the following metric:\n",
    "\n",
    "Let $X,Y$ be two rows of length $k$ in the data set. Assume that for all $i \\in [k]$, $X_i,Y_i \\in A_i$ ($A_i$ is a categorical field, for example the 'readmitted' field).\n",
    "\n",
    "Then: $d(X,Y)= \\sum_i \\mathbb{1}[X_i \\neq Y_i]$\n",
    "\n",
    "A cluster centroid will be a point $C \\in A_1 \\times A_2 \\times ... \\times A_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.  Using K-Modes to Cluster Patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-modes is a clustering algorithm which uses the metric defined above, and is closely related to K-Means.\n",
    "\n",
    "It uses the same type of expectation-maximization steps, but updates the centroids at each iteration by the \"mode\" of the categories, which is the category that has the highest count (within the cluster).\n",
    "\n",
    "For example, if $\\{X^1, X^2, X^3\\}$ are one cluster with centroid $C$, then our update will be:\n",
    "$$C_i=argmax_{c \\in A_i} (\\mathbb{1}[X^{1}_{i} = c]+ \\mathbb{1}[X^{2}_{i} = c] + \\mathbb{1}[X^{3}_{i} = c])$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cluster_df = pd.DataFrame({'res': encounters_train[['A1Cresult']]}, dtype=\"category\")\n",
    "diag_1 = encounters_train[['diag_1']]['diag_1'].astype(\"category\")\n",
    "diag_2 = encounters_train[['diag_2']]['diag_2'].astype(\"category\")\n",
    "diag_3 = encounters_train[['diag_3']]['diag_3'].astype(\"category\")\n",
    "A1Cres = encounters_train[['A1Cresult']]['A1Cresult'].astype(\"category\")\n",
    "readmitted = encounters_train[['readmitted']]['readmitted'].astype(\"category\")\n",
    "\n",
    "cols = {'diag_1': diag_1, 'diag_2': diag_2, 'diag_3': diag_3,\n",
    "        'A1Cres': A1Cres, 'readmitted': readmitted}\n",
    "cluster_df = pd.DataFrame(data = cols, dtype=\"category\")\n",
    "c1 = np.array(cluster_df.diag_1.cat.codes)\n",
    "c2 = np.array(cluster_df.diag_2.cat.codes)\n",
    "c3 = np.array(cluster_df.diag_3.cat.codes)\n",
    "c4 = np.array(cluster_df.A1Cres.cat.codes)\n",
    "c5 = np.array(cluster_df.readmitted.cat.codes)\n",
    "t = np.matrix([c1, c2, c3, c4, c5]).transpose()\n",
    "km = kmodes.KModes(n_clusters=4, init='Huang', n_init=5, verbose=1)\n",
    "clusters = km.fit_predict(t)\n",
    "print(km.cluster_centroids_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are going to cluster categorical data, a logical choice is to use the K-Modes algorithm.\n",
    "The algorithm uses the following metric:\n",
    "Let \n",
    "\n",
    "\n",
    "The specificts are at:\n",
    "\n",
    "    (1, 2) Huang, Z.: Clustering large data sets with mixed numeric and categorical values, Proceedings of the First Pacific Asia Knowledge Discovery and Data Mining Conference, Singapore, pp. 21-34, 1997.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get index<->category mappings:\n",
    "A1Cres_dict = dict( enumerate(cluster_df.A1Cres.cat.categories) )\n",
    "readmitted_dict = dict( enumerate(cluster_df.readmitted.cat.categories) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "centroids = pd.DataFrame(km.cluster_centroids_)\n",
    "# if needed, convert from index back to category:\n",
    "# centroids[3] = centroids[3].apply(lambda x: A1Cres_dict[x])\n",
    "# centroids[4] = centroids[4].apply(lambda x: readmitted_dict[x])\n",
    "print('Clusters (rows are clusters, columns are diag_1, diag_2, diag_3, A1Cresult, readmitted):')\n",
    "print(centroids)\n",
    "# Cluster info:\n",
    "cluster_labels = pd.Series(clusters, dtype=\"category\")\n",
    "print('\\nCluster sizes:')\n",
    "cluster_labels.groupby(cluster_labels).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got 4 pretty big clusters, and their centroids are described above (each row is a centroid)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the training data into 10 folds for cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "fold_idxs = []\n",
    "for train_idxs, test_idxs in kf.split(encounters_train):\n",
    "    fold_idxs.append({'train' : train_idxs, 'test': test_idxs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1. Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 0.888495924654\n",
      "Variance: 1.10207746337e-05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "scores = []\n",
    "for fold in fold_idxs:\n",
    "    train_facts = encounters_train.iloc[fold['train']].copy()\n",
    "    test_facts = encounters_train.iloc[fold['test']].copy()\n",
    "    cats_to_factorize = ['race', 'gender', 'age', 'weight', 'change', 'diabetesMed', 'A1Cresult']\n",
    "    train_facts[cats_to_factorize] = train_facts[cats_to_factorize].apply(lambda x: pd.factorize(x)[0]) \n",
    "    test_facts[cats_to_factorize] = test_facts[cats_to_factorize].apply(lambda x: pd.factorize(x)[0]) \n",
    "    features = ['race', 'gender', 'age', 'weight', 'change', 'diabetesMed', 'A1Cresult']\n",
    "    y_train_bool = train_facts.readmitted == '<30'\n",
    "    y_train = y_train_bool.values\n",
    "    X_train = train_facts[features].values\n",
    "    y_test_bool = test_facts.readmitted == '<30'\n",
    "    y_test = y_test_bool.values\n",
    "    X_test = test_facts[features].values\n",
    "    clf.fit(X_train,y_train)\n",
    "    scores.append(clf.score(X_test, y_test))\n",
    "print('Average: ' + str(np.average(scores)))\n",
    "print('Variance: ' + str(np.var(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.887540692513\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "train_facts = encounters_train.copy()\n",
    "test_facts = encounters_test.copy()\n",
    "cats_to_factorize = ['race', 'gender', 'age', 'weight', 'change', 'diabetesMed', 'A1Cresult']\n",
    "train_facts[cats_to_factorize] = train_facts[cats_to_factorize].apply(lambda x: pd.factorize(x)[0]) \n",
    "test_facts[cats_to_factorize] = test_facts[cats_to_factorize].apply(lambda x: pd.factorize(x)[0]) \n",
    "features = ['race', 'gender', 'age', 'weight', 'change', 'diabetesMed', 'A1Cresult']\n",
    "y_train_bool = train_facts.readmitted == '<30'\n",
    "y_train = y_train_bool.values\n",
    "X_train = train_facts[features].values\n",
    "y_test_bool = test_facts.readmitted == '<30'\n",
    "y_test = y_test_bool.values\n",
    "X_test = test_facts[features].values\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "print('Test accuracy: ' + str(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got test accuracy of $0.89$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2. General Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0.  43779.      0.]\n",
      " [     0.  31436.      0.]\n",
      " [     0.  16414.      0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix \n",
    "clf = MultinomialNB(class_prior = [0.05,0.6,0.35])\n",
    "conf_mat = np.zeros((3,3))\n",
    "\n",
    "for fold in fold_idxs:\n",
    "    train_facts = encounters_train.iloc[fold['train']].copy()\n",
    "    test_facts = encounters_train.iloc[fold['test']].copy()\n",
    "    cats_to_factorize = ['A1Cresult', 'diabetesMed', 'readmitted']\n",
    "    train_facts[cats_to_factorize] = train_facts[cats_to_factorize].apply(lambda x: pd.factorize(x)[0]) \n",
    "    test_facts[cats_to_factorize] = test_facts[cats_to_factorize].apply(lambda x: pd.factorize(x)[0]) \n",
    "    features = ['A1Cresult']\n",
    "    y_train = train_facts.readmitted.values\n",
    "    X_train = train_facts[features].values\n",
    "    y_test = test_facts.readmitted.values\n",
    "    X_test = test_facts[features].values\n",
    "    clf.fit(X_train,y_train)\n",
    "    conf_mat += confusion_matrix(y_test, clf.predict(X_test))\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying many different combinations of features, it seems that naïve bayes isn't the right choice for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.  3563.     0.]\n",
      " [    0.  5434.     0.]\n",
      " [    0.  1140.     0.]]\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(class_prior = [0.05,0.6,0.35])\n",
    "conf_mat = np.zeros((3,3))\n",
    "\n",
    "train_facts = encounters_train.copy()\n",
    "test_facts = encounters_test.copy()\n",
    "cats_to_factorize = ['A1Cresult', 'diabetesMed', 'readmitted']\n",
    "train_facts[cats_to_factorize] = train_facts[cats_to_factorize].apply(lambda x: pd.factorize(x)[0]) \n",
    "test_facts[cats_to_factorize] = test_facts[cats_to_factorize].apply(lambda x: pd.factorize(x)[0]) \n",
    "features = ['A1Cresult']\n",
    "y_train = train_facts.readmitted.values\n",
    "X_train = train_facts[features].values\n",
    "y_test = test_facts.readmitted.values\n",
    "X_test = test_facts[features].values\n",
    "clf.fit(X_train,y_train)\n",
    "conf_mat += confusion_matrix(y_test, clf.predict(X_test))\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that also on the test data our naïve bayes classifier isn't very accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task I am going to convert all the data to numerical data so I can use the Euclidean distance as a metric.\n",
    "This will be accomplished by defining \"dummy variables\" for the categorial data and leaving the numeric data as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_features = ['A1Cresult', 'insulin', 'change', 'diabetesMed']\n",
    "numer_features = ['number_emergency','num_procedures']\n",
    "all_features = cat_features + numer_features\n",
    "\n",
    "def het_data_to_numerical(sample_data):\n",
    "    df = pd.DataFrame()\n",
    "    cat_dfs = []\n",
    "    for cat_feat in cat_features:\n",
    "        cat_dfs.append(pd.get_dummies(sample_data[cat_feat], prefix=cat_feat))\n",
    "    raw_cat =  pd.concat([sample_data[numer_features]] + cat_dfs + [sample_data['readmitted']], axis=1)\n",
    "    return raw_cat.fillna(-1)\n",
    "\n",
    "    \n",
    "folds_with_dummy = []\n",
    "for fold in folds:\n",
    "    d = {'train': het_data_to_numerical(fold['train']), 'test':  het_data_to_numerical(fold['test'])}\n",
    "    folds_with_dummy.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1. Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10-fold validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folds_with_dummy[0]['train'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1. Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10-fold validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accs = []\n",
    "for fold in folds_with_dummy:\n",
    "    curr_train = fold['train'].copy()\n",
    "    curr_test = fold['test'].copy()\n",
    "    comb_features = set.union(set(curr_train.columns), set(curr_test.columns))\n",
    "    for new_c in comb_features - set(curr_train.columns):\n",
    "        curr_train[new_c] = -1\n",
    "    for new_c in comb_features - set(curr_test.columns):\n",
    "        curr_test[new_c] = -1\n",
    "\n",
    "    X = curr_train[[c for c in curr_train.columns if c != 'readmitted']].values\n",
    "    y = curr_train['readmitted'].values\n",
    "    y[y == -1] = 'NO'\n",
    "    y[y == '<30'] = 'YES'\n",
    "    y[y == '>30'] = 'NO'\n",
    "\n",
    "    r = RandomForestClassifier(n_estimators=100, class_weight={'NO': 90, 'YES': 1})\n",
    "    r.fit(X,y)\n",
    "\n",
    "    Xt = curr_test[[c for c in curr_train.columns if c != 'readmitted']].values\n",
    "    yt = curr_test['readmitted'].values\n",
    "    yt[yt == -1] = 'NO'\n",
    "    yt[yt == '<30'] = 'YES'\n",
    "    yt[yt == '>30'] = 'NO'\n",
    "    accs.append(r.score(Xt,yt))\n",
    "print('Average: ' + str(np.average(accs)))\n",
    "print('std: ' + str(np.std(accs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curr_train = het_data_to_numerical(encounters_train.copy())\n",
    "curr_test = het_data_to_numerical(encounters_test.copy())\n",
    "\n",
    "comb_features = set.union(set(curr_train.columns), set(curr_test.columns))\n",
    "for new_c in comb_features - set(curr_train.columns):\n",
    "    curr_train[new_c] = -1\n",
    "for new_c in comb_features - set(curr_test.columns):\n",
    "    curr_test[new_c] = -1\n",
    "\n",
    "X = curr_train[[c for c in curr_train.columns if c != 'readmitted']].values\n",
    "y = curr_train['readmitted'].values\n",
    "y[y == -1] = 'NO'\n",
    "y[y == '<30'] = 'YES'\n",
    "y[y == '>30'] = 'NO'\n",
    "\n",
    "r = RandomForestClassifier(n_estimators=100, class_weight={'NO': 90, 'YES': 1})\n",
    "r.fit(X,y)\n",
    "\n",
    "Xt = curr_test[[c for c in curr_train.columns if c != 'readmitted']].values\n",
    "yt = curr_test['readmitted'].values\n",
    "yt[yt == -1] = 'NO'\n",
    "yt[yt == '<30'] = 'YES'\n",
    "yt[yt == '>30'] = 'NO'\n",
    "print(r.score(Xt,yt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And our accuracy is $0.88$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2. General Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10-fold validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accs = []\n",
    "for fold in folds_with_dummy:\n",
    "    curr_train = fold['train']\n",
    "    curr_test = fold['test']\n",
    "    comb_features = set.union(set(curr_train.columns), set(curr_test.columns))\n",
    "    for new_c in comb_features - set(curr_train.columns):\n",
    "        curr_train[new_c] = -1\n",
    "    for new_c in comb_features - set(curr_test.columns):\n",
    "        curr_test[new_c] = -1\n",
    "\n",
    "    X = curr_train[[c for c in curr_train.columns if c != 'readmitted']].values\n",
    "    y = curr_train['readmitted'].values\n",
    "    y[y == -1] = 'NO'\n",
    "    r = RandomForestClassifier(n_estimators=100)\n",
    "    r.fit(X,y)\n",
    "\n",
    "    Xt = curr_test[[c for c in curr_train.columns if c != 'readmitted']]\n",
    "    yt = curr_test['readmitted'].values\n",
    "    yt[yt == -1] = 'NO'\n",
    "    y_pred = r.predict(Xt)\n",
    "    conf_mat = np.zeros((3,3))\n",
    "    l2i = {'<30':0, 'NO': 1, '>30': 2}\n",
    "    for i, y_p in enumerate(y_pred):\n",
    "        conf_mat[l2i[yt[i]], l2i[y_p]] += 1\n",
    "    print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the confusion matrices aren't ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curr_train = het_data_to_numerical(encounters_train.copy())\n",
    "curr_test = het_data_to_numerical(encounters_test.copy())\n",
    "comb_features = set.union(set(curr_train.columns), set(curr_test.columns))\n",
    "for new_c in comb_features - set(curr_train.columns):\n",
    "    curr_train[new_c] = -1\n",
    "for new_c in comb_features - set(curr_test.columns):\n",
    "    curr_test[new_c] = -1\n",
    "\n",
    "X = curr_train[[c for c in curr_train.columns if c != 'readmitted']].values\n",
    "y = curr_train['readmitted'].values\n",
    "y[y == -1] = 'NO'\n",
    "r = RandomForestClassifier(n_estimators=100)\n",
    "r.fit(X,y)\n",
    "\n",
    "Xt = curr_test[[c for c in curr_train.columns if c != 'readmitted']]\n",
    "yt = curr_test['readmitted'].values\n",
    "yt[yt == -1] = 'NO'\n",
    "y_pred = r.predict(Xt)\n",
    "conf_mat = np.zeros((3,3))\n",
    "l2i = {'<30':0, 'NO': 1, '>30': 2}\n",
    "for i, y_p in enumerate(y_pred):\n",
    "    conf_mat[l2i[yt[i]], l2i[y_p]] += 1\n",
    "print(conf_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
